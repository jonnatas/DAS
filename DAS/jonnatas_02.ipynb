{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonnatas/workspace_python/caffe/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from StringIO import StringIO\n",
    "import urllib\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "caffe_root = '/home/jonnatas/workspace_python/caffe/'\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "print caffe_root\n",
    "\n",
    "import caffe\n",
    "\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n"
     ]
    }
   ],
   "source": [
    "caffe.set_mode_cpu()\n",
    "\n",
    "model_def = os.path.join(caffe_root, 'models', 'bvlc_reference_caffenet','deploy.prototxt')\n",
    "model_weights = os.path.join(caffe_root, 'models','bvlc_reference_caffenet','bvlc_reference_caffenet.caffemodel')\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)\n",
    "\n",
    "mu = np.load(os.path.join(caffe_root, 'python','caffe','imagenet','ilsvrc_2012_mean.npy'))\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n",
    "\n",
    "net.blobs['data'].reshape(50,        # batch size\n",
    "                          3,         # 3-channel (BGR) images\n",
    "                          227, 227)  # image size is 227x227\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printFaces(faces,coordinates):\n",
    "    print('Total of faces detected = '+str(len(faces)))\n",
    "    \n",
    "    print 'coordinates: '\n",
    "    for coordinate in coordinates:\n",
    "        x,y,w,h = coordinate\n",
    "        print [(x,y), (x+w,y+h), (x+w, y), (x, y+h)]\n",
    "        print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contFaces(faces,frame,DOWNSCALE):\n",
    "    coordinates = []\n",
    "    # print 'face detected!'\n",
    "    for i in faces:\n",
    "        x, y, w, h = [ v*DOWNSCALE for v in i ]\n",
    "\n",
    "        coordinates.append((x,y,w,h))\n",
    "        print x,y,w,h\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0))\n",
    "    \n",
    "    return coordinates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    height, width, depth = frame.shape\n",
    "   \n",
    "    # create grayscale version\n",
    "    grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # equalize histogram\n",
    "    cv2.equalizeHist(grayscale, grayscale)\n",
    "    \n",
    "    # detect objects\n",
    "    classifier = cv2.CascadeClassifier(\"/usr/local/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "    \n",
    "    DOWNSCALE = 4\n",
    "    minisize = (frame.shape[1]/DOWNSCALE,frame.shape[0]/DOWNSCALE)\n",
    "    miniframe = cv2.resize(frame, minisize)\n",
    "    faces = classifier.detectMultiScale(miniframe)\n",
    "    coordinates = []\n",
    "    \n",
    "    if len(faces)>0:\n",
    "        coordinates = contFaces(faces,frame,DOWNSCALE)\n",
    "        # print 'face detected!'\n",
    "        \n",
    "    printFaces(faces, coordinates)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_url(url):\n",
    "        cap = cv2.VideoCapture(url)\n",
    "        ret,img = cap.read()\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_image_camera():\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if (cap==True):\n",
    "            print(\"deu certo\")\n",
    "            \n",
    "        while(True):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "            img = frame.copy()\n",
    "            # Call the function\n",
    "            frame = detect(frame)\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('frame',frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cv2.imwrite(\"frame.jpg\", frame)\n",
    "        cv2.imwrite(os.path.join(caffe_root, 'examples', 'images','frame.jpg'), frame)\n",
    "\n",
    "        \n",
    "        # When everything done, release the capture\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        cap = cv2\n",
    "\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cats_and_dogs_probability(output_prob, labels, path_animal):\n",
    "        labels_animal = np.loadtxt(path_animal, str, delimiter='\\t')\n",
    "        \n",
    "        index = 0\n",
    "        list_animal = []\n",
    "        probability_animal = 0.0\n",
    "        \n",
    "        for i in labels:\n",
    "                if i in labels_animal:\n",
    "                        list_animal.append((output_prob[index],labels[index]))\n",
    "                        probability_animal += output_prob[index]\n",
    "                index += 1\n",
    "        list_animal = sorted(list_animal, reverse=True)\n",
    "        \n",
    "        for i in list_animal:\n",
    "            probability , animal_class = i\n",
    "            print 'Synset ' + str(animal_class)\n",
    "            print 'Probability ' + str(probability * 100.0) + \"%\"\n",
    "        \n",
    "        return probability_animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probability(image):    \n",
    "        transformed_image = transformer.preprocess('data', image)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # copy the image data into the memory allocated for the net\n",
    "        net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "        ### perform classification\n",
    "        output = net.forward()\n",
    "\n",
    "        output_prob = output['prob'][0]  # the output probability vector for the first image in the batch\n",
    "\n",
    "        print 'predicted class is:', output_prob.argmax()   \n",
    "\n",
    "        # print 'predicted class is:', output_prob.argmax()\n",
    "        \n",
    "        # load ImageNet labels\n",
    "        labels_file = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "   \n",
    "        labels = np.loadtxt(labels_file, str, delimiter='\\t')\n",
    "\n",
    "        dogs_file = os.path.join(caffe_root, 'data','ilsvrc12','dogs.txt')\n",
    "        cats_file = os.path.join(caffe_root, 'data', 'ilsvrc12','cats.txt')\n",
    "\n",
    "        top_inds = output_prob.argsort()[::-1][:]\n",
    "\n",
    "        probability_dogs = cats_and_dogs_probability(output_prob, labels, dogs_file)\n",
    "        probability_cats = cats_and_dogs_probability(output_prob, labels, cats_file)\n",
    "               \n",
    "        print '\\n\\n::Results::\\n'\n",
    "        print 'Feline probability: ' + str( (probability_cats) * 100.0 ) + \"%\"\n",
    "        print 'Canine probability: ' + str( (probability_dogs) * 100.0 ) + \"%\"\n",
    "        print 'Most probable synset:', labels[output_prob.argmax()]\n",
    "        print 'Compatibility: ' + str(output_prob[output_prob.argmax()] * 100.0) + \"%\"\n",
    "        print '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def options():\n",
    "        print('1 - image')\n",
    "        print('2 - url')\n",
    "        print('3 - camera')\n",
    "        print('4 - exit')\n",
    "\n",
    "        return int(raw_input(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def option_image():\n",
    "        image_name = raw_input('File name:\\n')\n",
    "\n",
    "        image = cv2.VideoCapture(image_name)\n",
    "        ret, img = image.read()\n",
    "\n",
    "        # detect(img)\n",
    "\n",
    "        image_recognition = caffe.io.load_image(image_name)\n",
    "\n",
    "        probability(image_recognition)\n",
    "        image_detected = detect(img)\n",
    "\n",
    "        plt.imshow(image_detected[:,:,::-1])\n",
    "        plt.title('Detection result')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def option_url():\n",
    "        image_url = raw_input('enter the image url:\\n')\n",
    "        image = get_image_url(image_url)\n",
    "\n",
    "        urllib.urlretrieve(image_url, os.path.join(caffe_root, 'examples', 'images','url.jpg'))\n",
    "        image_recognition = caffe.io.load_image(os.path.join(caffe_root, 'examples', 'images','url.jpg'))\n",
    "        # print image\n",
    "\n",
    "        probability(image_recognition)\n",
    "        image_detected = detect(image)\n",
    "\n",
    "        plt.imshow(image_detected[:,:,::-1])\n",
    "        plt.title('Detection result')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def option_camera():\n",
    "        frame = get_image_camera()\n",
    "        image_recognition = caffe.io.load_image(os.path.join(caffe_root, 'examples', 'images','frame.jpg'))\n",
    "        probability(image_recognition)\n",
    "        image_detected = detect(frame)\n",
    "\n",
    "        plt.imshow(image_detected[:,:,::-1])\n",
    "        plt.title('Detection result')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_printFaces():\n",
    "     printFaces(faces, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - image\n",
      "2 - url\n",
      "3 - camera\n",
      "4 - exit\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "        while True:\n",
    "                option = options()\n",
    "\n",
    "                if option == 1:\n",
    "                    option_image()\n",
    "\n",
    "                elif option == 2:\n",
    "                     option_url()\n",
    "\n",
    "                elif option == 3:\n",
    "                    option_camera()\n",
    "\n",
    "                elif option == 4:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
